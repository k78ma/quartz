---
title: ML Fundamentals
tags:
  - ml
date: 2024-01-14
aliases:
---
Never a bad idea to brush up my ML/DL fundamentals; trying to build my knowledge from the ground up in a Feynman-like way. Notes are mostly from [MIT 6.036x](https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/course/), [Understanding Deep Learning](https://udlbook.github.io/udlbook/) and [Deep Learning - Foundations and Concepts](https://www.bishopbook.com/)

### Classification
- [[Linear Classifier]]
	- [[Perceptron|Perceptron]]
		- [[Averaged Perceptron|Averaged Perceptron]]
		- [[Perceptron Convergence Theorem|Perceptron Convergence Theorem]]
- [[Margin|Margin]]
- [[Logistic Regression]]
	- [[Gradient Descent for Logistic Regression]]
- [[Support Vector Machine]]
### Features
- [[Feature Representation|Feature Representation]]
	- [[Feature Engineering|Feature Engineering]]
	- [[Polynomial Basis|Polynomial Basis]]
### Activation Functions
- [[Activation Function]]
	- [[Sigmoid]]
	- [[Rectified Linear Unit]]
	- [[Step function]]
	- [[Hyperbolic Tangent]]
	- [[Softmax]]
- [[Output Activation Functions]]
### Loss Functions
- [[Machine Learning as Optimization]]
- [[Loss Function]]
- [[Negative log-likelihood]]
	- [[Negative log-likelihood multi-class]]
- [[Hinge Loss]]
### Regularization
- [[Regularization]]
- [[L1 Regularization]]
- [[L2 Regularization]]
- [[Early stopping]]
- [[Weight Decay]]
- [[Weight Perturbation]]
- [[Dropout]]
- [[Batch Normalization]]
### Regression
- [[Regression]]
- [[Ordinary Least Squares]]
- [[Ridge Regression]]
### Gradient Descent
- [[Gradient Descent]]
	- [[1D Gradient Descent]]
	- [[Multiple Dimension Gradient Descent]]
- [[Stochastic Gradient Descent]]
- [[Batch Gradient Descent]]
### Neural Networks
- [[Neural Networks]]
	- [[Artificial Neuron]]
	- [[Single-layer Neural Network]]
	- [[Multi-layer Neural Network]]
- [[Universal Approximation Theorem]]
- [[Backpropagation]] 
- [[Neural Network Training]]
- [[Neural Network Weight Initialization]]
### Optimizing Neural Network Parameters
- [[Adaptive step-size]]
	- [[Running Averages]]
	- [[Momentum (ML)]]
	- [[Adadelta|Adagrad/Adadelta]]
	- [[Adam]]
### Convolutional Neural Networks
- [[Convolutional Neural Networks]]
	- [[Image Filters]]
	- [[Max Pooling]]
	- [[CNN Architecture]]
### Recurrent Networks
- [[Recurrent Neural Networks]]
- [[Long Term Short Memory|LSTM]]
### Problems
- [[MIT 6.036x Problems]]
- [[SYDE 572 Problems]]
- [[UDL Problems]]
